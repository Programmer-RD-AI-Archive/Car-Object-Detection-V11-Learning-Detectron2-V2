{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509463cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor,DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "PROJECT_NAME = 'Car-Object-Detection-V11-Learning-Detectron2-V2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fab8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351ac3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               image        xmin        ymin        xmax        ymax\n",
      "0     vid_4_1000.jpg  281.259045  187.035071  327.727931  223.225547\n",
      "1    vid_4_10000.jpg   15.163531  187.035071  120.329957  236.430180\n",
      "2    vid_4_10040.jpg  239.192475  176.764801  361.968162  236.430180\n",
      "3    vid_4_10020.jpg  496.483358  172.363256  630.020260  231.539575\n",
      "4    vid_4_10060.jpg   16.630970  186.546010  132.558611  238.386422\n",
      "..               ...         ...         ...         ...         ...\n",
      "554   vid_4_9860.jpg    0.000000  198.321729   49.235251  236.223284\n",
      "555   vid_4_9880.jpg  329.876184  156.482351  536.664239  250.497895\n",
      "556   vid_4_9900.jpg    0.000000  168.295823  141.797524  239.176652\n",
      "557   vid_4_9960.jpg  487.428988  172.233646  616.917699  228.839864\n",
      "558   vid_4_9980.jpg  221.558631  182.570434  348.585579  238.192196\n",
      "\n",
      "[559 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d19439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite(crop,'./crop.png')\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f7340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef85192",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite(crop,'./crop.png')\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fd7be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559"
     ]
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31010d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               image        xmin        ymin        xmax        ymax\n",
      "0     vid_4_1000.jpg  281.259045  187.035071  327.727931  223.225547\n",
      "1    vid_4_10000.jpg   15.163531  187.035071  120.329957  236.430180\n",
      "2    vid_4_10040.jpg  239.192475  176.764801  361.968162  236.430180\n",
      "3    vid_4_10020.jpg  496.483358  172.363256  630.020260  231.539575\n",
      "4    vid_4_10060.jpg   16.630970  186.546010  132.558611  238.386422\n",
      "..               ...         ...         ...         ...         ...\n",
      "554   vid_4_9860.jpg    0.000000  198.321729   49.235251  236.223284\n",
      "555   vid_4_9880.jpg  329.876184  156.482351  536.664239  250.497895\n",
      "556   vid_4_9900.jpg    0.000000  168.295823  141.797524  239.176652\n",
      "557   vid_4_9960.jpg  487.428988  172.233646  616.917699  228.839864\n",
      "558   vid_4_9980.jpg  221.558631  182.570434  348.585579  238.192196\n",
      "\n",
      "[559 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4140ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['xmin'].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f30b1dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype('float64')"
     ]
    }
   ],
   "source": [
    "data['xmin'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be530268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      281\n",
      "1       15\n",
      "2      239\n",
      "3      496\n",
      "4       16\n",
      "      ... \n",
      "554      0\n",
      "555    329\n",
      "556      0\n",
      "557    487\n",
      "558    221\n",
      "Name: xmin, Length: 559, dtype: int64"
     ]
    }
   ],
   "source": [
    "data['xmin'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c448192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['xmin'] = data['xmin'].astype(int)\n",
    "data['ymin'] = data['ymin'].astype(int)\n",
    "data['xmax'] = data['xmax'].astype(int)\n",
    "data['ymax'] = data['ymax'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3df8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite(crop,'./crop.png')\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7b5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14722a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['xmin'] = data['xmin'].astype(int)\n",
    "data['ymin'] = data['ymin'].astype(int)\n",
    "data['xmax'] = data['xmax'].astype(int)\n",
    "data['ymax'] = data['ymax'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18e88f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite(crop,'./crop.png')\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f732123",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('./crop.png',crop)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)\n",
    "cv2.imwrite('./box.png',box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c49aae07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('./crop.png',crop)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)\n",
    "cv2.imwrite('./box.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d384629",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2eaae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['xmin'] = data['xmin'].astype(int)\n",
    "data['ymin'] = data['ymin'].astype(int)\n",
    "data['xmax'] = data['xmax'].astype(int)\n",
    "data['ymax'] = data['ymax'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a46285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('./crop.png',crop)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)\n",
    "cv2.imwrite('./box.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "772264f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6526b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a389ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['xmin'] = data['xmin'].astype(int)\n",
    "data['ymin'] = data['ymin'].astype(int)\n",
    "data['xmax'] = data['xmax'].astype(int)\n",
    "data['ymax'] = data['ymax'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a5e7715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('./crop.png',crop)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)\n",
    "cv2.imwrite('./box.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "472831ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = data.iloc[185]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18dce718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['xmin'] = data['xmin'].astype(int)\n",
    "data['ymin'] = data['ymin'].astype(int)\n",
    "data['xmax'] = data['xmax'].astype(int)\n",
    "data['ymax'] = data['ymax'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74dbdfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./data/' + info['image'])\n",
    "xmin,ymin,xmax,ymax = info['xmin'],info['ymin'],info['xmax'],info['ymax']\n",
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin\n",
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('./crop.png',crop)\n",
    "cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2)\n",
    "cv2.imwrite('./box.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40bf4e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    records = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        record = {}\n",
    "        info = data.iloc[i]\n",
    "        path = './data/' + info['image']\n",
    "        record['file_name'] = path\n",
    "        record['height'],record['width'] = cv2.imread(path).shape[:2]\n",
    "        record['image_id'] = i\n",
    "        record['annotations'] = [\n",
    "            {\n",
    "                'bbox':[info['xmin'],info['ymin'],info['xmax'],info['ymax']],\n",
    "                'bbox_mode':BoxMode.XYXY_ABS,\n",
    "                'category_id':0\n",
    "            }\n",
    "        ]\n",
    "        records.append(record)\n",
    "    np.save(records,'./data.npy')\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d40684",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4de26966",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register('data',lambda : load_data())\n",
    "MetadataCatalog.get('data').set(thing_classes=labels)\n",
    "metadata = MetadataCatalog.get('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dab4e973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V11-Learning-Detectron2-V2/runs/3eq23tds\" target=\"_blank\">baseline</a></strong> to <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V11-Learning-Detectron2-V2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "cfg.DATASETS.TRAIN = ('data')\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.MAX_ITER = 500\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "cfg.MODEL.WEIGHTS = './output/model_final.pth'\n",
    "evaluator = COCOEvaluator('data',output_dir='./output/')\n",
    "val_loader = build_detection_test_loader(cfg,'data')\n",
    "metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "wandb.log(metrics)\n",
    "img = cv2.imread('./data/vid_4_12220.jpg')\n",
    "preds = predictor(img)\n",
    "v = Visualizer(img[:,:,::-1],metadata=metadata)\n",
    "v = v.draw_instance_predictions(preds['instances'].to('cpu'))\n",
    "v = v.get_image()[:,:,::-1]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(v)\n",
    "plt.savefig('./img.png')\n",
    "plt.close()\n",
    "wandb.log({'Img':wandb.Image(cv2.imread('./img.png'))})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "194b42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd8f2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(model))\n",
    "cfg.DATASETS.TRAIN = ('data')\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.MAX_ITER = 500\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(labels)\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "predictor = DefaultPredictor(cfg)\n",
    "cfg.MODEL.WEIGHTS = './output/model_final.pth'\n",
    "evaluator = COCOEvaluator('data',output_dir='./output/')\n",
    "val_loader = build_detection_test_loader(cfg,'data')\n",
    "metrics = inference_on_dataset(predictor.model,val_loader,evaluator)\n",
    "wandb.log(metrics)\n",
    "img = cv2.imread('./data/vid_4_12220.jpg')\n",
    "preds = predictor(img)\n",
    "v = Visualizer(img[:,:,::-1],metadata=metadata)\n",
    "v = v.draw_instance_predictions(preds['instances'].to('cpu'))\n",
    "v = v.get_image()[:,:,::-1]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(v)\n",
    "plt.savefig('./img.png')\n",
    "plt.close()\n",
    "wandb.log({'Img':wandb.Image(cv2.imread('./img.png'))})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
